{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h73vTw8dXjRC"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6In8XSCSIdK"
      },
      "outputs": [],
      "source": [
        "! pip install ftfy regex tqdm\n",
        "! pip install git+https://github.com/openai/CLIP.git\n",
        "\n",
        "import os\n",
        "import clip\n",
        "import torch\n",
        "import pickle\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from pkg_resources import packaging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Obhum68Ori0M"
      },
      "outputs": [],
      "source": [
        "# Download the dataset used\n",
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "!unzip tiny-imagenet-200.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79yysQnU-GgE"
      },
      "source": [
        "# Model loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUkvQNlMMnTU"
      },
      "outputs": [],
      "source": [
        "model, preprocess = clip.load(\"RN50x4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLQv1MbSziSJ"
      },
      "outputs": [],
      "source": [
        "class ModifiedResNetTraverser:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.target_layer_name = None\n",
        "        self.target_layer = None\n",
        "\n",
        "    def find_layer_by_name(self, target_layer_name):\n",
        "        self.target_layer_name = target_layer_name\n",
        "        self.target_layer = None\n",
        "        self._traverse(self.model, target_layer_name.split('.'))\n",
        "        return self.target_layer\n",
        "\n",
        "    def _traverse(self, module, layer_names):\n",
        "        if not layer_names:\n",
        "            # If there are no more layer names, we've reached the target layer\n",
        "            self.target_layer = module\n",
        "            return\n",
        "\n",
        "        current_layer_name = layer_names[0]\n",
        "        remaining_layer_names = layer_names[1:]\n",
        "\n",
        "        for name, sub_module in module.named_children():\n",
        "            if name == current_layer_name:\n",
        "                # Continue traversing with the next layer name\n",
        "                self._traverse(sub_module, remaining_layer_names)\n",
        "\n",
        "# Example usage\n",
        "traverser = ModifiedResNetTraverser(model)\n",
        "target_layer_name = \"visual.layer4.5.conv3\"\n",
        "last_conv_layer = traverser.find_layer_by_name(target_layer_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFRHC2NmzlKZ"
      },
      "outputs": [],
      "source": [
        "class SaveActivations:\n",
        "    def __init__(self):\n",
        "        self.activations = None\n",
        "\n",
        "    def __call__(self, module, input, output):\n",
        "        self.activations = output.clone()\n",
        "\n",
        "# Create an instance of the hook\n",
        "hook = SaveActivations()\n",
        "\n",
        "hook_handle = last_conv_layer.register_forward_hook(hook)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ7UudhV9lGJ"
      },
      "source": [
        "\n",
        "\n",
        "# Which neurons activate?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IL5LmSsWgpX"
      },
      "outputs": [],
      "source": [
        "def get_most_responding_neurons(files, k=25):\n",
        "  my_activations = []\n",
        "  filenames = []\n",
        "  for filename in files:\n",
        "    filenames.append(filename)  # Store filename\n",
        "    photo = Image.open(filename).convert(\"RGB\")\n",
        "    photo_vec = preprocess(photo)\n",
        "    input = torch.stack([photo_vec]).cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "      hook = SaveActivations()\n",
        "      hook_handle = last_conv_layer.register_forward_hook(hook)\n",
        "      image_features = model.encode_image(input)\n",
        "      #mean:\n",
        "      #mean_values = torch.mean(hook.activations[0], dim=(1, 2), keepdim=False)\n",
        "      #max:\n",
        "      max_values, _ = torch.max(hook.activations[0].view(hook.activations[0].size(0), -1), dim=1)\n",
        "      my_activations.append(max_values) #mean_values or max_values accordingly\n",
        "      hook_handle.remove()\n",
        "\n",
        "  hook_neural_activation = torch.stack(my_activations)\n",
        "  values, tops = hook_neural_activation.topk(k, dim = 0)\n",
        "  tops_filenames = [[filenames[i] for i in top] for top in tops]\n",
        "  return tops_filenames, values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDa_uEEwJTyB"
      },
      "outputs": [],
      "source": [
        "## One subfolder\n",
        "image_dir = '/content/img_align_celeba'\n",
        "batch_size = 50\n",
        "image_files = os.listdir(image_dir)\n",
        "image_files = [os.path.join(image_dir, f) for f in image_files]\n",
        "image_batches = [image_files[i:i+50] for i in range(0, len(image_files), 50)]\n",
        "all_tops = []\n",
        "all_values = []\n",
        "\n",
        "for i,batch in enumerate(image_batches):\n",
        "    tops, values = get_most_responding_neurons(batch)\n",
        "    all_tops.append(tops)\n",
        "    all_values.append(values)\n",
        "\n",
        "# Using filenames directly\n",
        "stacked_tops = [item for sublist in all_tops for item in sublist]\n",
        "stacked_values = torch.cat(all_values, dim=0)\n",
        "\n",
        "top_values, top_indices = torch.topk(stacked_values, k=25, dim=0)\n",
        "selected_tops = [[stacked_tops[i][j] for i in range(5)] for j in top_indices[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksj9DSFGfcqp"
      },
      "outputs": [],
      "source": [
        "# Plotting top images and their activation\n",
        "neuron_idx = 0\n",
        "for i,file in enumerate(selected_tops[neuron_idx]):\n",
        "  print(top_values[i,neuron_idx].cpu().detach().numpy())\n",
        "  image = Image.open(file).resize((100,100))\n",
        "  display(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoHopDF3g1q4"
      },
      "outputs": [],
      "source": [
        "## All subfolders\n",
        "parent_dir = '/content/tiny-imagenet-200/train/'\n",
        "batch_size = 50\n",
        "all_tops = []\n",
        "all_values = []\n",
        "\n",
        "for subfolder in tqdm(os.listdir(parent_dir)):\n",
        "    subfolder_path = os.path.join(parent_dir, subfolder)\n",
        "    if os.path.isdir(subfolder_path):\n",
        "        image_dir = os.path.join(subfolder_path, 'images')\n",
        "\n",
        "        # Process images in the 'images' folder of each subfolder\n",
        "        image_files = os.listdir(image_dir)\n",
        "        image_files = [os.path.join(image_dir, f) for f in image_files]\n",
        "        image_batches = [image_files[i:i+batch_size] for i in range(0, len(image_files), batch_size)]\n",
        "\n",
        "        # Process each batch of images\n",
        "        for batch in image_batches:\n",
        "            tops, values = get_most_responding_neurons(batch)\n",
        "            all_tops.append(tops)\n",
        "            all_values.append(values)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_tops = [item for sublist in all_tops for item in sublist]\n",
        "stacked_values = torch.cat(all_values, dim=0)\n",
        "top_values, top_indices = torch.topk(stacked_values, k=25, dim=0)\n",
        "top_indices_list = top_indices.tolist()\n",
        "top_indices_transposed = list(map(list, zip(*top_indices_list)))\n",
        "\n",
        "selected_filenames = []\n",
        "for i, indices in enumerate(top_indices_transposed):\n",
        "    elements = [stacked_tops[index][i] for index in indices]\n",
        "    selected_filenames.append(elements)"
      ],
      "metadata": {
        "id": "W1SjaZ2YBWSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lhkaJCkhtIQ"
      },
      "outputs": [],
      "source": [
        "# Plotting top images and their activations in 5x5\n",
        "neuron_idx = 129\n",
        "fig, axs = plt.subplots(5, 5, figsize=(8, 8))\n",
        "for i, file in enumerate(selected_filenames[neuron_idx]):\n",
        "    row_index = i // 5\n",
        "    col_index = i % 5\n",
        "\n",
        "    image = Image.open(file).resize((200, 200))\n",
        "\n",
        "    axs[row_index, col_index].imshow(image)\n",
        "    #axs[row_index, col_index].set_title(f'Activation: {top_values[i, neuron_idx]:.3f}')\n",
        "    axs[row_index, col_index].axis('off')\n",
        "\n",
        "#fig.suptitle(f'Image samples for neuron: {neuron_idx}')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing on our own datasets regarding Donald Trump and Mental Illness"
      ],
      "metadata": {
        "id": "ORv6fhNE1Brm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subfolder_names = [\"profile\", \"art\", \"text\", \"partial\", \"politics\", \"non political\", \"rights\", \"music-games\"]\n",
        "batch_size = 30\n",
        "all_tops = []\n",
        "all_values = []\n",
        "image_files = []\n",
        "\n",
        "for subfolder in subfolder_names:\n",
        "    folder_path = os.path.join(\"/content/drive/MyDrive/patrec/trump\", subfolder)\n",
        "\n",
        "    for filename in [filename for filename in os.listdir(folder_path) if filename.endswith(\".png\") or filename.endswith(\".jpg\")]:\n",
        "        image = os.path.join(folder_path, filename)\n",
        "        image_files.append(image)\n",
        "\n",
        "image_batches = [image_files[i:i+batch_size] for i in range(0, len(image_files), batch_size)]\n",
        "\n",
        "# Process each batch of images\n",
        "for batch in image_batches:\n",
        "    tops, values = get_most_responding_neurons(batch,25)\n",
        "    all_tops.append(tops)\n",
        "    all_values.append(values)"
      ],
      "metadata": {
        "id": "OxBv1s5l1FQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_tops = [item for sublist in all_tops for item in sublist]\n",
        "stacked_values = torch.cat(all_values, dim=0)\n",
        "top_values, top_indices = torch.topk(stacked_values, k=15, dim=0)\n",
        "top_indices_list = top_indices.tolist()\n",
        "top_indices_transposed = list(map(list, zip(*top_indices_list)))\n",
        "\n",
        "selected_filenames = []\n",
        "for i, indices in enumerate(top_indices_transposed):\n",
        "    elements = [stacked_tops[index][i] for index in indices]\n",
        "    selected_filenames.append(elements)"
      ],
      "metadata": {
        "id": "LXZZVrpx6xWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting top images and their activations in 5x5\n",
        "neuron_idx = 89\n",
        "fig, axs = plt.subplots(3, 5, figsize=(8, 8))\n",
        "for i, file in enumerate(selected_filenames[neuron_idx]):\n",
        "    row_index = i // 5\n",
        "    col_index = i % 5\n",
        "\n",
        "    image = Image.open(file).resize((200, 200))\n",
        "\n",
        "    axs[row_index, col_index].imshow(image)\n",
        "    #axs[row_index, col_index].set_title(f'Activation: {top_values[i, neuron_idx]:.3f}')\n",
        "    axs[row_index, col_index].axis('off')\n",
        "\n",
        "fig.suptitle(f'Image samples for neuron: {neuron_idx}')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XxbABHGJ2Tc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subfolder_names = [\"depression\", \"anxiety\", \"bad feeling\", \"psychology\", \"drugs\", \"unrelated\", \"travel-food-pet\", \"music-sports\"]\n",
        "batch_size = 30\n",
        "all_tops = []\n",
        "all_values = []\n",
        "image_files = []\n",
        "\n",
        "for subfolder in subfolder_names:\n",
        "    folder_path = os.path.join(\"/content/drive/MyDrive/patrec/mental illness\", subfolder)\n",
        "\n",
        "    for filename in [filename for filename in os.listdir(folder_path) if filename.endswith(\".png\") or filename.endswith(\".jpg\")]:\n",
        "        image = os.path.join(folder_path, filename)\n",
        "        image_files.append(image)\n",
        "\n",
        "image_batches = [image_files[i:i+batch_size] for i in range(0, len(image_files), batch_size)]\n",
        "\n",
        "# Process each batch of images\n",
        "for batch in image_batches:\n",
        "    k = 25\n",
        "    if len(batch) < 25:\n",
        "        k = len(batch)\n",
        "    tops, values = get_most_responding_neurons(batch, k)\n",
        "    all_tops.append(tops)\n",
        "    all_values.append(values)"
      ],
      "metadata": {
        "id": "iF8VE5Sz4JtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_tops = [item for sublist in all_tops for item in sublist]\n",
        "stacked_values = torch.cat(all_values, dim=0)\n",
        "top_values, top_indices = torch.topk(stacked_values, k=15, dim=0)\n",
        "top_indices_list = top_indices.tolist()\n",
        "top_indices_transposed = list(map(list, zip(*top_indices_list)))\n",
        "\n",
        "selected_filenames = []\n",
        "for i, indices in enumerate(top_indices_transposed):\n",
        "    elements = [stacked_tops[index][i] for index in indices]\n",
        "    selected_filenames.append(elements)"
      ],
      "metadata": {
        "id": "0oCpUPTw_PUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting top images and their activations in 5x5\n",
        "neuron_idx = 2191\n",
        "fig, axs = plt.subplots(3, 5, figsize=(8, 8))\n",
        "for i, file in enumerate(selected_filenames[neuron_idx]):\n",
        "    row_index = i // 5\n",
        "    col_index = i % 5\n",
        "\n",
        "    image = Image.open(file).resize((200, 200))\n",
        "\n",
        "    axs[row_index, col_index].imshow(image)\n",
        "    #axs[row_index, col_index].set_title(f'Activation: {top_values[i, neuron_idx]:.3f}')\n",
        "    axs[row_index, col_index].axis('off')\n",
        "\n",
        "fig.suptitle(f'Image samples for neuron: {neuron_idx}')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SoE8-oG35Tcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpjHwPEq9d6d"
      },
      "source": [
        "# Text Images"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We created images with the names of ImageNet classes written on them to test if CLIP neurons also respond to text"
      ],
      "metadata": {
        "id": "dWlcEE5tYsSV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXV4SaFbqS1z"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "imagenet_labels = requests.get(\"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\").json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVNp18Sup5ac"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "output_directory = \"/content/drive/MyDrive/patrec/ClassNames\"\n",
        "# Create the output directory if it doesn't exist\n",
        "if not os.path.exists(output_directory):\n",
        "    os.makedirs(output_directory)\n",
        "\n",
        "def create_pattern_image(text, text_color):\n",
        "    # Define image dimensions\n",
        "    width, height = 400, 200\n",
        "\n",
        "    # Create a white background image\n",
        "    image = np.ones((height, width, 3), dtype=np.uint8) * 255\n",
        "\n",
        "    # Choose font and scale\n",
        "    # font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    # font = cv2.FONT_HERSHEY_SCRIPT_COMPLEX\n",
        "    # font = cv2.FONT_HERSHEY_DUPLEX\n",
        "    font = cv2.FONT_HERSHEY_COMPLEX\n",
        "    font_scale = 2\n",
        "\n",
        "    # Get the size of the text\n",
        "    text_size = cv2.getTextSize(text, font, font_scale, 2)[0]\n",
        "\n",
        "    # Calculate text position to be centered\n",
        "    text_x = (width - text_size[0]) // 2\n",
        "    text_y = (height + text_size[1]) // 2\n",
        "\n",
        "    # Write the text on the image with specified color\n",
        "    cv2.putText(image, text, (text_x, text_y), font, font_scale, text_color, 2, cv2.LINE_AA)\n",
        "\n",
        "    return image\n",
        "\n",
        "def save_image(image, text, color_name):\n",
        "    # Save the image to a file\n",
        "    dir = output_directory\n",
        "    if not os.path.exists(dir):\n",
        "        os.makedirs(dir)\n",
        "    filename = f\"{color_name}.png\"\n",
        "    filepath = os.path.join(dir, filename)\n",
        "    cv2.imwrite(filepath, image)\n",
        "    print(f\"Image with {color_name} text saved as {filename}\")\n",
        "\n",
        "# Generate and save images for each color\n",
        "for label in imagenet_labels:\n",
        "    pattern_image = create_pattern_image(label, (0,0,0))\n",
        "    save_image(pattern_image, label, label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZMFr_Hisihs"
      },
      "outputs": [],
      "source": [
        "## All subfolders\n",
        "folders = [\"/content/drive/MyDrive/patrec/ClassNames\", \"/content/drive/MyDrive/patrec/ClassNames2\", \"/content/drive/MyDrive/patrec/ClassNames3\", \"/content/drive/MyDrive/patrec/ClassNames4\"]\n",
        "parent_dir = \"/content/drive/MyDrive/patrec/ClassNames\"\n",
        "batch_size = 50\n",
        "all_tops = []\n",
        "all_values = []\n",
        "\n",
        "for subfolder in tqdm(folders):\n",
        "    if os.path.isdir(subfolder):\n",
        "        image_dir = subfolder\n",
        "\n",
        "        # Process images in the 'images' folder of each subfolder\n",
        "        image_files = os.listdir(image_dir)\n",
        "        image_files = [os.path.join(image_dir, f) for f in image_files]\n",
        "        image_batches = [image_files[i:i+batch_size] for i in range(0, len(image_files), batch_size)]\n",
        "\n",
        "        # Process each batch of images\n",
        "        for batch in image_batches:\n",
        "            tops, values = get_most_responding_neurons(batch)\n",
        "            all_tops.append(tops)\n",
        "            all_values.append(values)\n",
        "\n",
        "'''\n",
        "# Process images\n",
        "image_files = os.listdir(parent_dir)\n",
        "image_files = [os.path.join(parent_dir, f) for f in image_files]\n",
        "image_batches = [image_files[i:i+batch_size] for i in range(0, len(image_files), batch_size)]\n",
        "\n",
        "# Process each batch of images\n",
        "for batch in image_batches:\n",
        "    tops, values = get_most_responding_neurons(batch)\n",
        "    all_tops.append(tops)\n",
        "    all_values.append(values)\n",
        "'''\n",
        "\n",
        "stacked_tops = [item for sublist in all_tops for item in sublist]\n",
        "stacked_values = torch.cat(all_values, dim=0)\n",
        "top_values, top_indices = torch.topk(stacked_values, k=25, dim=0)\n",
        "top_indices_list = top_indices.tolist()\n",
        "top_indices_transposed = list(map(list, zip(*top_indices_list)))\n",
        "\n",
        "selected_files = []\n",
        "for indices in top_indices_transposed:\n",
        "    elements = [stacked_tops[index][i] for i, index in enumerate(indices)]\n",
        "    selected_files.append(elements)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTkYFK0Tuyxg"
      },
      "outputs": [],
      "source": [
        "# Plotting top images and their activations in 5x5\n",
        "neuron_idx = 48\n",
        "fig, axs = plt.subplots(5, 5, figsize=(8, 8))\n",
        "for i, file in enumerate(selected_files[neuron_idx]):\n",
        "    row_index = i // 5\n",
        "    col_index = i % 5\n",
        "\n",
        "    image = Image.open(file).resize((400, 200))\n",
        "\n",
        "    axs[row_index, col_index].imshow(image)\n",
        "    axs[row_index, col_index].set_title(f'Activation: {top_values[i, neuron_idx]:.3f}')\n",
        "    axs[row_index, col_index].axis('off')\n",
        "\n",
        "fig.suptitle(f'Text Image samples for neuron: {neuron_idx}')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}